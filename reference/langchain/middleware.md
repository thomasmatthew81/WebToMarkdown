[![logo](https://reference.langchain.com/python/static/brand/reference-light.svg)
![logo](https://reference.langchain.com/python/static/brand/reference-dark.svg)](https://reference.langchain.com/python/ "LangChain Reference")
LangChain Reference

[langchain-ai/docs

* 100
* 820](https://github.com/langchain-ai/docs "Go to repository")

* [Get started](https://reference.langchain.com/python/)
* [LangChain](https://reference.langchain.com/python/langchain/)

  LangChain
  + [langchain](https://reference.langchain.com/python/langchain/langchain/)

    langchain
    - [Agents](https://reference.langchain.com/python/langchain/agents/)
    - Middleware

      [Middleware](https://reference.langchain.com/python/langchain/middleware/)



      Table of contents
      * [Middleware classes](https://reference.langchain.com/python/langchain/middleware/#middleware-classes)
      * [Decorators](https://reference.langchain.com/python/langchain/middleware/#decorators)
      * [Types and utilities](https://reference.langchain.com/python/langchain/middleware/#types-and-utilities)
      * [SummarizationMiddleware](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.SummarizationMiddleware)

        + [\_\_init\_\_](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.SummarizationMiddleware.__init__)
      * [HumanInTheLoopMiddleware](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.HumanInTheLoopMiddleware)

        + [\_\_init\_\_](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.HumanInTheLoopMiddleware.__init__)
      * [ModelCallLimitMiddleware](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ModelCallLimitMiddleware)

        + [state\_schema](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ModelCallLimitMiddleware.state_schema)
        + [\_\_init\_\_](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ModelCallLimitMiddleware.__init__)
      * [ToolCallLimitMiddleware](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ToolCallLimitMiddleware)

        + [state\_schema](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ToolCallLimitMiddleware.state_schema)
        + [\_\_init\_\_](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ToolCallLimitMiddleware.__init__)
      * [ModelFallbackMiddleware](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ModelFallbackMiddleware)

        + [\_\_init\_\_](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ModelFallbackMiddleware.__init__)
      * [PIIMiddleware](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.PIIMiddleware)

        + [\_\_init\_\_](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.PIIMiddleware.__init__)
      * [TodoListMiddleware](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.TodoListMiddleware)

        + [state\_schema](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.TodoListMiddleware.state_schema)
        + [\_\_init\_\_](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.TodoListMiddleware.__init__)
      * [LLMToolSelectorMiddleware](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.LLMToolSelectorMiddleware)

        + [\_\_init\_\_](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.LLMToolSelectorMiddleware.__init__)
      * [ToolRetryMiddleware](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ToolRetryMiddleware)

        + [\_\_init\_\_](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ToolRetryMiddleware.__init__)
      * [LLMToolEmulator](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.LLMToolEmulator)

        + [\_\_init\_\_](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.LLMToolEmulator.__init__)
      * [ContextEditingMiddleware](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ContextEditingMiddleware)

        + [\_\_init\_\_](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ContextEditingMiddleware.__init__)
      * [ShellToolMiddleware](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ShellToolMiddleware)

        + [\_\_init\_\_](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ShellToolMiddleware.__init__)
      * [FilesystemFileSearchMiddleware](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.FilesystemFileSearchMiddleware)

        + [\_\_init\_\_](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.FilesystemFileSearchMiddleware.__init__)
    - [Models](https://reference.langchain.com/python/langchain/models/)
    - [Messages](https://reference.langchain.com/python/langchain/messages/)
    - [Tools](https://reference.langchain.com/python/langchain/tools/)
    - [Embeddings](https://reference.langchain.com/python/langchain/embeddings/)
  + [langchain-core](https://reference.langchain.com/python/langchain_core/)

    langchain-core
    - [Caches](https://reference.langchain.com/python/langchain_core/caches/)
    - [Callbacks](https://reference.langchain.com/python/langchain_core/callbacks/)
    - [Documents](https://reference.langchain.com/python/langchain_core/documents/)
    - [Document loaders](https://reference.langchain.com/python/langchain_core/document_loaders/)
    - [Embeddings](https://reference.langchain.com/python/langchain_core/embeddings/)
    - [Exceptions](https://reference.langchain.com/python/langchain_core/exceptions/)
    - [Language models](https://reference.langchain.com/python/langchain_core/language_models/)
    - [Serialization](https://reference.langchain.com/python/langchain_core/load/)
    - [Output parsers](https://reference.langchain.com/python/langchain_core/output_parsers/)
    - [Prompts](https://reference.langchain.com/python/langchain_core/prompts/)
    - [Rate limiters](https://reference.langchain.com/python/langchain_core/rate_limiters/)
    - [Retrievers](https://reference.langchain.com/python/langchain_core/retrievers/)
    - [Runnables](https://reference.langchain.com/python/langchain_core/runnables/)
    - [Utilities](https://reference.langchain.com/python/langchain_core/utils/)
    - [Vector stores](https://reference.langchain.com/python/langchain_core/vectorstores/)
  + [langchain-text-splitters](https://reference.langchain.com/python/langchain_text_splitters/)

    langchain-text-splitters
  + [langchain-mcp-adapters](https://reference.langchain.com/python/langchain_mcp_adapters/)

    langchain-mcp-adapters
  + [langchain-model-profiles](https://reference.langchain.com/python/langchain_model_profiles/)

    langchain-model-profiles
  + [langchain-tests](https://reference.langchain.com/python/langchain_tests/)

    langchain-tests
    - [Unit tests](https://reference.langchain.com/python/langchain_tests/unit_tests/)
    - [Integration tests](https://reference.langchain.com/python/langchain_tests/integration_tests/)
  + [langchain-classic](https://reference.langchain.com/python/langchain_classic/)

    langchain-classic
    - [Agents](https://reference.langchain.com/python/langchain_classic/agents/)
    - [Callbacks](https://reference.langchain.com/python/langchain_classic/callbacks/)
    - [Chains](https://reference.langchain.com/python/langchain_classic/chains/)
    - [Chat models](https://reference.langchain.com/python/langchain_classic/chat_models/)
    - [Embeddings](https://reference.langchain.com/python/langchain_classic/embeddings/)
    - [Evaluation](https://reference.langchain.com/python/langchain_classic/evaluation/)
    - [Globals](https://reference.langchain.com/python/langchain_classic/globals/)
    - [Hub](https://reference.langchain.com/python/langchain_classic/hub/)
    - [Memory](https://reference.langchain.com/python/langchain_classic/memory/)
    - [Output parsers](https://reference.langchain.com/python/langchain_classic/output_parsers/)
    - [Retrievers](https://reference.langchain.com/python/langchain_classic/retrievers/)
    - [Runnables](https://reference.langchain.com/python/langchain_classic/runnables/)
    - [LangSmith](https://reference.langchain.com/python/langchain_classic/smith/)
    - [Storage](https://reference.langchain.com/python/langchain_classic/storage/)
* [LangGraph](https://reference.langchain.com/python/langgraph/)
* [Deep Agents](https://reference.langchain.com/python/deepagents/)
* [Integrations](https://reference.langchain.com/python/integrations/)
* [LangSmith](https://reference.langchain.com/python/langsmith/)

Table of contents

* [Middleware classes](https://reference.langchain.com/python/langchain/middleware/#middleware-classes)
* [Decorators](https://reference.langchain.com/python/langchain/middleware/#decorators)
* [Types and utilities](https://reference.langchain.com/python/langchain/middleware/#types-and-utilities)
* [SummarizationMiddleware](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.SummarizationMiddleware " SummarizationMiddleware")

  + [\_\_init\_\_](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.SummarizationMiddleware.__init__)
* [HumanInTheLoopMiddleware](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.HumanInTheLoopMiddleware " HumanInTheLoopMiddleware")

  + [\_\_init\_\_](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.HumanInTheLoopMiddleware.__init__)
* [ModelCallLimitMiddleware](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ModelCallLimitMiddleware " ModelCallLimitMiddleware")

  + [state\_schema](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ModelCallLimitMiddleware.state_schema)
  + [\_\_init\_\_](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ModelCallLimitMiddleware.__init__)
* [ToolCallLimitMiddleware](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ToolCallLimitMiddleware)

  + [state\_schema](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ToolCallLimitMiddleware.state_schema)
  + [\_\_init\_\_](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ToolCallLimitMiddleware.__init__)
* [ModelFallbackMiddleware](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ModelFallbackMiddleware " ModelFallbackMiddleware")

  + [\_\_init\_\_](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ModelFallbackMiddleware.__init__)
* [PIIMiddleware](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.PIIMiddleware)

  + [\_\_init\_\_](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.PIIMiddleware.__init__)
* [TodoListMiddleware](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.TodoListMiddleware)

  + [state\_schema](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.TodoListMiddleware.state_schema)
  + [\_\_init\_\_](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.TodoListMiddleware.__init__)
* [LLMToolSelectorMiddleware](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.LLMToolSelectorMiddleware)

  + [\_\_init\_\_](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.LLMToolSelectorMiddleware.__init__)
* [ToolRetryMiddleware](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ToolRetryMiddleware)

  + [\_\_init\_\_](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ToolRetryMiddleware.__init__)
* [LLMToolEmulator](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.LLMToolEmulator)

  + [\_\_init\_\_](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.LLMToolEmulator.__init__)
* [ContextEditingMiddleware](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ContextEditingMiddleware)

  + [\_\_init\_\_](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ContextEditingMiddleware.__init__)
* [ShellToolMiddleware](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ShellToolMiddleware)

  + [\_\_init\_\_](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ShellToolMiddleware.__init__)
* [FilesystemFileSearchMiddleware](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.FilesystemFileSearchMiddleware)

  + [\_\_init\_\_](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.FilesystemFileSearchMiddleware.__init__)

# Middleware

Reference docs

This page contains **reference documentation** for Middleware. See [the docs](https://docs.langchain.com/oss/python/langchain/middleware) for conceptual guides, tutorials, and examples on using Middleware.

## Middleware classes[¶](https://reference.langchain.com/python/langchain/middleware/#middleware-classes "Copy anchor link to this section for reference")

LangChain provides prebuilt middleware for common agent use cases:

| CLASS | DESCRIPTION |
| --- | --- |
| [`SummarizationMiddleware`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.SummarizationMiddleware) | Automatically summarize conversation history when approaching token limits |
| [`HumanInTheLoopMiddleware`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.HumanInTheLoopMiddleware) | Pause execution for human approval of tool calls |
| [`ModelCallLimitMiddleware`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ModelCallLimitMiddleware) | Limit the number of model calls to prevent excessive costs |
| [`ToolCallLimitMiddleware`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ToolCallLimitMiddleware) | Control tool execution by limiting call counts |
| [`ModelFallbackMiddleware`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ModelFallbackMiddleware) | Automatically fallback to alternative models when primary fails |
| [`PIIMiddleware`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.PIIMiddleware) | Detect and handle Personally Identifiable Information |
| [`TodoListMiddleware`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.TodoListMiddleware) | Equip agents with task planning and tracking capabilities |
| [`LLMToolSelectorMiddleware`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.LLMToolSelectorMiddleware) | Use an LLM to select relevant tools before calling main model |
| [`ToolRetryMiddleware`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ToolRetryMiddleware) | Automatically retry failed tool calls with exponential backoff |
| [`LLMToolEmulator`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.LLMToolEmulator) | Emulate tool execution using LLM for testing purposes |
| [`ContextEditingMiddleware`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ContextEditingMiddleware) | Manage conversation context by trimming or clearing tool uses |
| [`ShellToolMiddleware`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ShellToolMiddleware) | Expose a persistent shell session to agents for command execution |
| [`FilesystemFileSearchMiddleware`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.FilesystemFileSearchMiddleware) | Provide Glob and Grep search tools over filesystem files |
| [`AgentMiddleware`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.AgentMiddleware) | Base middleware class for creating custom middleware |

## Decorators[¶](https://reference.langchain.com/python/langchain/middleware/#decorators "Copy anchor link to this section for reference")

Create custom middleware using these decorators:

| DECORATOR | DESCRIPTION |
| --- | --- |
| [`@before_agent`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.before_agent) | Execute logic before agent execution starts |
| [`@before_model`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.before_model) | Execute logic before each model call |
| [`@after_model`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.after_model) | Execute logic after each model receives a response |
| [`@after_agent`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.after_agent) | Execute logic after agent execution completes |
| [`@wrap_model_call`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.wrap_model_call) | Wrap and intercept model calls |
| [`@wrap_tool_call`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.wrap_tool_call) | Wrap and intercept tool calls |
| [`@dynamic_prompt`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.dynamic_prompt) | Generate dynamic system prompts based on request context |
| [`@hook_config`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.hook_config) | Configure hook behavior (e.g., conditional routing) |

## Types and utilities[¶](https://reference.langchain.com/python/langchain/middleware/#types-and-utilities "Copy anchor link to this section for reference")

Core types for building middleware:

| TYPE | DESCRIPTION |
| --- | --- |
| [`AgentState`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.AgentState) | State container for agent execution |
| [`ModelRequest`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ModelRequest) | Request details passed to model calls |
| [`ModelResponse`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ModelResponse) | Response details from model calls |
| [`ClearToolUsesEdit`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ClearToolUsesEdit) | Utility for clearing tool usage history from context |
| [`InterruptOnConfig`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.InterruptOnConfig) | Configuration for human-in-the-loop interruptions |



## langchain.agents.middleware.SummarizationMiddleware [¶](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.SummarizationMiddleware "Copy anchor link to this section for reference")

Summarizes conversation history when token limits are approached.

This middleware monitors message token counts and automatically summarizes older
messages when a threshold is reached, preserving recent messages and maintaining
context continuity by ensuring AI/Tool message pairs remain together.

| METHOD | DESCRIPTION |
| --- | --- |
| `__init__` | Initialize summarization middleware. |

### \_\_init\_\_ [¶](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.SummarizationMiddleware.__init__ "Copy anchor link to this section for reference")

```
__init__(
    model: str | BaseChatModel,
    *,
    trigger: ContextSize | list[ContextSize] | None = None,
    keep: ContextSize = ("messages", _DEFAULT_MESSAGES_TO_KEEP),
    token_counter: TokenCounter = count_tokens_approximately,
    summary_prompt: str = DEFAULT_SUMMARY_PROMPT,
    trim_tokens_to_summarize: int | None = _DEFAULT_TRIM_TOKEN_LIMIT,
    **deprecated_kwargs: Any,
) -> None
```

Initialize summarization middleware.

| PARAMETER | DESCRIPTION |
| --- | --- |
| `model` | The language model to use for generating summaries.  **TYPE:** `str | BaseChatModel` |
| `trigger` | One or more thresholds that trigger summarization. Provide a single `ContextSize` tuple or a list of tuples, in which case summarization runs when any threshold is breached. Examples: `("messages", 50)`, `("tokens", 3000)`, `[("fraction", 0.8), ("messages", 100)]`.  **TYPE:** `ContextSize | list[ContextSize] | None`  **DEFAULT:** `None` |
| `keep` | Context retention policy applied after summarization. Provide a `ContextSize` tuple to specify how much history to preserve. Defaults to keeping the most recent 20 messages. Examples: `("messages", 20)`, `("tokens", 3000)`, or `("fraction", 0.3)`.  **TYPE:** `ContextSize`  **DEFAULT:** `('messages', _DEFAULT_MESSAGES_TO_KEEP)` |
| `token_counter` | Function to count tokens in messages.  **TYPE:** `TokenCounter`  **DEFAULT:** `count_tokens_approximately` |
| `summary_prompt` | Prompt template for generating summaries.  **TYPE:** `str`  **DEFAULT:** `DEFAULT_SUMMARY_PROMPT` |
| `trim_tokens_to_summarize` | Maximum tokens to keep when preparing messages for the summarization call. Pass `None` to skip trimming entirely.  **TYPE:** `int | None`  **DEFAULT:** `_DEFAULT_TRIM_TOKEN_LIMIT` |

## langchain.agents.middleware.HumanInTheLoopMiddleware [¶](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.HumanInTheLoopMiddleware "Copy anchor link to this section for reference")

Human in the loop middleware.

| METHOD | DESCRIPTION |
| --- | --- |
| `__init__` | Initialize the human in the loop middleware. |

### \_\_init\_\_ [¶](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.HumanInTheLoopMiddleware.__init__ "Copy anchor link to this section for reference")

```
__init__(
    interrupt_on: dict[str, bool | InterruptOnConfig],
    *,
    description_prefix: str = "Tool execution requires approval",
) -> None
```

Initialize the human in the loop middleware.

| PARAMETER | DESCRIPTION |
| --- | --- |
| `interrupt_on` | Mapping of tool name to allowed actions.  If a tool doesn't have an entry, it's auto-approved by default.   * `True` indicates all decisions are allowed: approve, edit, and reject. * `False` indicates that the tool is auto-approved. * `InterruptOnConfig` indicates the specific decisions allowed for this   tool.  The `InterruptOnConfig` can include a `description` field (`str` or   `Callable`) for custom formatting of the interrupt description.  **TYPE:** `dict[str, bool | InterruptOnConfig]` |
| `description_prefix` | The prefix to use when constructing action requests.  This is used to provide context about the tool call and the action being requested.  Not used if a tool has a `description` in its `InterruptOnConfig`.  **TYPE:** `str`  **DEFAULT:** `'Tool execution requires approval'` |

## langchain.agents.middleware.ModelCallLimitMiddleware [¶](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ModelCallLimitMiddleware "Copy anchor link to this section for reference")

Tracks model call counts and enforces limits.

This middleware monitors the number of model calls made during agent execution
and can terminate the agent when specified limits are reached. It supports
both thread-level and run-level call counting with configurable exit behaviors.

Thread-level: The middleware tracks the number of model calls and persists
call count across multiple runs (invocations) of the agent.

Run-level: The middleware tracks the number of model calls made during a single
run (invocation) of the agent.

Example

```
from langchain.agents.middleware.call_tracking import ModelCallLimitMiddleware
from langchain.agents import create_agent

# Create middleware with limits
call_tracker = ModelCallLimitMiddleware(thread_limit=10, run_limit=5, exit_behavior="end")

agent = create_agent("openai:gpt-4o", middleware=[call_tracker])

# Agent will automatically jump to end when limits are exceeded
result = await agent.invoke({"messages": [HumanMessage("Help me with a task")]})
```

| METHOD | DESCRIPTION |
| --- | --- |
| `__init__` | Initialize the call tracking middleware. |

### state\_schema `class-attribute` `instance-attribute` [¶](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ModelCallLimitMiddleware.state_schema "Copy anchor link to this section for reference")

```
state_schema = ModelCallLimitState
```

The schema for state passed to the middleware nodes.

### \_\_init\_\_ [¶](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ModelCallLimitMiddleware.__init__ "Copy anchor link to this section for reference")

```
__init__(
    *,
    thread_limit: int | None = None,
    run_limit: int | None = None,
    exit_behavior: Literal["end", "error"] = "end",
) -> None
```

Initialize the call tracking middleware.

| PARAMETER | DESCRIPTION |
| --- | --- |
| `thread_limit` | Maximum number of model calls allowed per thread.  `None` means no limit.  **TYPE:** `int | None`  **DEFAULT:** `None` |
| `run_limit` | Maximum number of model calls allowed per run.  `None` means no limit.  **TYPE:** `int | None`  **DEFAULT:** `None` |
| `exit_behavior` | What to do when limits are exceeded. - `'end'`: Jump to the end of the agent execution and inject an artificial AI message indicating that the limit was exceeded. - `'error'`: Raise a `ModelCallLimitExceededError`  **TYPE:** `Literal['end', 'error']`  **DEFAULT:** `'end'` |

| RAISES | DESCRIPTION |
| --- | --- |
| `ValueError` | If both limits are `None` or if `exit_behavior` is invalid. |

## langchain.agents.middleware.ToolCallLimitMiddleware [¶](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ToolCallLimitMiddleware "Copy anchor link to this section for reference")

Track tool call counts and enforces limits during agent execution.

This middleware monitors the number of tool calls made and can terminate or
restrict execution when limits are exceeded. It supports both thread-level
(persistent across runs) and run-level (per invocation) call counting.

Configuration

* `exit_behavior`: How to handle when limits are exceeded
  + `'continue'`: Block exceeded tools, let execution continue (default)
  + `'error'`: Raise an exception
  + `'end'`: Stop immediately with a `ToolMessage` + AI message for the single
    tool call that exceeded the limit (raises `NotImplementedError` if there
    are other pending tool calls (due to parallel tool calling).

Examples:

Continue execution with blocked tools (default)

```
from langchain.agents.middleware.tool_call_limit import ToolCallLimitMiddleware
from langchain.agents import create_agent

# Block exceeded tools but let other tools and model continue
limiter = ToolCallLimitMiddleware(
    thread_limit=20,
    run_limit=10,
    exit_behavior="continue",  # default
)

agent = create_agent("openai:gpt-4o", middleware=[limiter])
```

Stop immediately when limit exceeded

```
# End execution immediately with an AI message
limiter = ToolCallLimitMiddleware(run_limit=5, exit_behavior="end")

agent = create_agent("openai:gpt-4o", middleware=[limiter])
```

Raise exception on limit

```
# Strict limit with exception handling
limiter = ToolCallLimitMiddleware(tool_name="search", thread_limit=5, exit_behavior="error")

agent = create_agent("openai:gpt-4o", middleware=[limiter])

try:
    result = await agent.invoke({"messages": [HumanMessage("Task")]})
except ToolCallLimitExceededError as e:
    print(f"Search limit exceeded: {e}")
```

| METHOD | DESCRIPTION |
| --- | --- |
| `__init__` | Initialize the tool call limit middleware. |

### state\_schema `class-attribute` `instance-attribute` [¶](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ToolCallLimitMiddleware.state_schema "Copy anchor link to this section for reference")

```
state_schema = ToolCallLimitState
```

The schema for state passed to the middleware nodes.

### \_\_init\_\_ [¶](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ToolCallLimitMiddleware.__init__ "Copy anchor link to this section for reference")

```
__init__(
    *,
    tool_name: str | None = None,
    thread_limit: int | None = None,
    run_limit: int | None = None,
    exit_behavior: ExitBehavior = "continue",
) -> None
```

Initialize the tool call limit middleware.

| PARAMETER | DESCRIPTION |
| --- | --- |
| `tool_name` | Name of the specific tool to limit. If `None`, limits apply to all tools.  **TYPE:** `str | None`  **DEFAULT:** `None` |
| `thread_limit` | Maximum number of tool calls allowed per thread. `None` means no limit.  **TYPE:** `int | None`  **DEFAULT:** `None` |
| `run_limit` | Maximum number of tool calls allowed per run. `None` means no limit.  **TYPE:** `int | None`  **DEFAULT:** `None` |
| `exit_behavior` | How to handle when limits are exceeded. - `'continue'`: Block exceeded tools with error messages, let other tools continue. Model decides when to end. - `'error'`: Raise a `ToolCallLimitExceededError` exception - `'end'`: Stop execution immediately with a `ToolMessage` + AI message for the single tool call that exceeded the limit. Raises `NotImplementedError` if there are multiple parallel tool calls to other tools or multiple pending tool calls.  **TYPE:** `ExitBehavior`  **DEFAULT:** `'continue'` |

| RAISES | DESCRIPTION |
| --- | --- |
| `ValueError` | If both limits are `None`, if `exit_behavior` is invalid, or if `run_limit` exceeds thread\_limit. |

## langchain.agents.middleware.ModelFallbackMiddleware [¶](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ModelFallbackMiddleware "Copy anchor link to this section for reference")

Automatic fallback to alternative models on errors.

Retries failed model calls with alternative models in sequence until
success or all models exhausted. Primary model specified in `create_agent`.

Example

```
from langchain.agents.middleware.model_fallback import ModelFallbackMiddleware
from langchain.agents import create_agent

fallback = ModelFallbackMiddleware(
    "openai:gpt-4o-mini",  # Try first on error
    "anthropic:claude-sonnet-4-5-20250929",  # Then this
)

agent = create_agent(
    model="openai:gpt-4o",  # Primary model
    middleware=[fallback],
)

# If primary fails: tries gpt-4o-mini, then claude-sonnet-4-5-20250929
result = await agent.invoke({"messages": [HumanMessage("Hello")]})
```

| METHOD | DESCRIPTION |
| --- | --- |
| `__init__` | Initialize model fallback middleware. |

### \_\_init\_\_ [¶](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ModelFallbackMiddleware.__init__ "Copy anchor link to this section for reference")

```
__init__(
    first_model: str | BaseChatModel, *additional_models: str | BaseChatModel
) -> None
```

Initialize model fallback middleware.

| PARAMETER | DESCRIPTION |
| --- | --- |
| `first_model` | First fallback model (string name or instance).  **TYPE:** `str | BaseChatModel` |
| `*additional_models` | Additional fallbacks in order.  **TYPE:** `str | BaseChatModel`  **DEFAULT:** `()` |

## langchain.agents.middleware.PIIMiddleware [¶](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.PIIMiddleware "Copy anchor link to this section for reference")

Detect and handle Personally Identifiable Information (PII) in conversations.

This middleware detects common PII types and applies configurable strategies
to handle them. It can detect emails, credit cards, IP addresses, MAC addresses, and
URLs in both user input and agent output.

Built-in PII types:

* `email`: Email addresses
* `credit_card`: Credit card numbers (validated with Luhn algorithm)
* `ip`: IP addresses (validated with stdlib)
* `mac_address`: MAC addresses
* `url`: URLs (both `http`/`https` and bare URLs)

Strategies:

* `block`: Raise an exception when PII is detected
* `redact`: Replace PII with `[REDACTED_TYPE]` placeholders
* `mask`: Partially mask PII (e.g., `****-****-****-1234` for credit card)
* `hash`: Replace PII with deterministic hash (e.g., `<email_hash:a1b2c3d4>`)

Strategy Selection Guide:

| Strategy | Preserves Identity? | Best For |
| --- | --- | --- |
| `block` | N/A | Avoid PII completely |
| `redact` | No | General compliance, log sanitization |
| `mask` | No | Human readability, customer service UIs |
| `hash` | Yes (pseudonymous) | Analytics, debugging |

Example

```
from langchain.agents.middleware import PIIMiddleware
from langchain.agents import create_agent

# Redact all emails in user input
agent = create_agent(
    "openai:gpt-5",
    middleware=[
        PIIMiddleware("email", strategy="redact"),
    ],
)

# Use different strategies for different PII types
agent = create_agent(
    "openai:gpt-4o",
    middleware=[
        PIIMiddleware("credit_card", strategy="mask"),
        PIIMiddleware("url", strategy="redact"),
        PIIMiddleware("ip", strategy="hash"),
    ],
)

# Custom PII type with regex
agent = create_agent(
    "openai:gpt-5",
    middleware=[
        PIIMiddleware("api_key", detector=r"sk-[a-zA-Z0-9]{32}", strategy="block"),
    ],
)
```

| METHOD | DESCRIPTION |
| --- | --- |
| `__init__` | Initialize the PII detection middleware. |

### \_\_init\_\_ [¶](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.PIIMiddleware.__init__ "Copy anchor link to this section for reference")

```
__init__(
    pii_type: Literal["email", "credit_card", "ip", "mac_address", "url"] | str,
    *,
    strategy: Literal["block", "redact", "mask", "hash"] = "redact",
    detector: Callable[[str], list[PIIMatch]] | str | None = None,
    apply_to_input: bool = True,
    apply_to_output: bool = False,
    apply_to_tool_results: bool = False,
) -> None
```

Initialize the PII detection middleware.

| PARAMETER | DESCRIPTION |
| --- | --- |
| `pii_type` | Type of PII to detect.  Can be a built-in type (`email`, `credit_card`, `ip`, `mac_address`, `url`) or a custom type name.  **TYPE:** `Literal['email', 'credit_card', 'ip', 'mac_address', 'url'] | str` |
| `strategy` | How to handle detected PII.  Options:   * `block`: Raise `PIIDetectionError` when PII is detected * `redact`: Replace with `[REDACTED_TYPE]` placeholders * `mask`: Partially mask PII (show last few characters) * `hash`: Replace with deterministic hash (format: `<type_hash:digest>`)  **TYPE:** `Literal['block', 'redact', 'mask', 'hash']`  **DEFAULT:** `'redact'` |
| `detector` | Custom detector function or regex pattern.   * If `Callable`: Function that takes content string and returns   list of `PIIMatch` objects * If `str`: Regex pattern to match PII * If `None`: Uses built-in detector for the `pii_type`  **TYPE:** `Callable[[str], list[PIIMatch]] | str | None`  **DEFAULT:** `None` |
| `apply_to_input` | Whether to check user messages before model call.  **TYPE:** `bool`  **DEFAULT:** `True` |
| `apply_to_output` | Whether to check AI messages after model call.  **TYPE:** `bool`  **DEFAULT:** `False` |
| `apply_to_tool_results` | Whether to check tool result messages after tool execution.  **TYPE:** `bool`  **DEFAULT:** `False` |

| RAISES | DESCRIPTION |
| --- | --- |
| `ValueError` | If `pii_type` is not built-in and no detector is provided. |

## langchain.agents.middleware.TodoListMiddleware [¶](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.TodoListMiddleware "Copy anchor link to this section for reference")

Middleware that provides todo list management capabilities to agents.

This middleware adds a `write_todos` tool that allows agents to create and manage
structured task lists for complex multi-step operations. It's designed to help
agents track progress, organize complex tasks, and provide users with visibility
into task completion status.

The middleware automatically injects system prompts that guide the agent on when
and how to use the todo functionality effectively.

Example

```
from langchain.agents.middleware.todo import TodoListMiddleware
from langchain.agents import create_agent

agent = create_agent("openai:gpt-4o", middleware=[TodoListMiddleware()])

# Agent now has access to write_todos tool and todo state tracking
result = await agent.invoke({"messages": [HumanMessage("Help me refactor my codebase")]})

print(result["todos"])  # Array of todo items with status tracking
```

| PARAMETER | DESCRIPTION |
| --- | --- |
| `system_prompt` | Custom system prompt to guide the agent on using the todo tool.  **TYPE:** `str`  **DEFAULT:** `WRITE_TODOS_SYSTEM_PROMPT` |
| `tool_description` | Custom description for the write\_todos tool.  **TYPE:** `str`  **DEFAULT:** `WRITE_TODOS_TOOL_DESCRIPTION` |

| METHOD | DESCRIPTION |
| --- | --- |
| `__init__` | Initialize the `TodoListMiddleware` with optional custom prompts. |

### state\_schema `class-attribute` `instance-attribute` [¶](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.TodoListMiddleware.state_schema "Copy anchor link to this section for reference")

```
state_schema = PlanningState
```

The schema for state passed to the middleware nodes.

### \_\_init\_\_ [¶](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.TodoListMiddleware.__init__ "Copy anchor link to this section for reference")

```
__init__(
    *,
    system_prompt: str = WRITE_TODOS_SYSTEM_PROMPT,
    tool_description: str = WRITE_TODOS_TOOL_DESCRIPTION,
) -> None
```

Initialize the `TodoListMiddleware` with optional custom prompts.

| PARAMETER | DESCRIPTION |
| --- | --- |
| `system_prompt` | Custom system prompt to guide the agent on using the todo tool.  **TYPE:** `str`  **DEFAULT:** `WRITE_TODOS_SYSTEM_PROMPT` |
| `tool_description` | Custom description for the `write_todos` tool.  **TYPE:** `str`  **DEFAULT:** `WRITE_TODOS_TOOL_DESCRIPTION` |

## langchain.agents.middleware.LLMToolSelectorMiddleware [¶](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.LLMToolSelectorMiddleware "Copy anchor link to this section for reference")

Uses an LLM to select relevant tools before calling the main model.

When an agent has many tools available, this middleware filters them down
to only the most relevant ones for the user's query. This reduces token usage
and helps the main model focus on the right tools.

Examples:

Limit to 3 tools

```
from langchain.agents.middleware import LLMToolSelectorMiddleware

middleware = LLMToolSelectorMiddleware(max_tools=3)

agent = create_agent(
    model="openai:gpt-4o",
    tools=[tool1, tool2, tool3, tool4, tool5],
    middleware=[middleware],
)
```

Use a smaller model for selection

```
middleware = LLMToolSelectorMiddleware(model="openai:gpt-4o-mini", max_tools=2)
```

| METHOD | DESCRIPTION |
| --- | --- |
| `__init__` | Initialize the tool selector. |

### \_\_init\_\_ [¶](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.LLMToolSelectorMiddleware.__init__ "Copy anchor link to this section for reference")

```
__init__(
    *,
    model: str | BaseChatModel | None = None,
    system_prompt: str = DEFAULT_SYSTEM_PROMPT,
    max_tools: int | None = None,
    always_include: list[str] | None = None,
) -> None
```

Initialize the tool selector.

| PARAMETER | DESCRIPTION |
| --- | --- |
| `model` | Model to use for selection.  If not provided, uses the agent's main model.  Can be a model identifier string or `BaseChatModel` instance.  **TYPE:** `str | BaseChatModel | None`  **DEFAULT:** `None` |
| `system_prompt` | Instructions for the selection model.  **TYPE:** `str`  **DEFAULT:** `DEFAULT_SYSTEM_PROMPT` |
| `max_tools` | Maximum number of tools to select.  If the model selects more, only the first `max_tools` will be used.  No limit if not specified.  **TYPE:** `int | None`  **DEFAULT:** `None` |
| `always_include` | Tool names to always include regardless of selection.  These do not count against the `max_tools` limit.  **TYPE:** `list[str] | None`  **DEFAULT:** `None` |

## langchain.agents.middleware.ToolRetryMiddleware [¶](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ToolRetryMiddleware "Copy anchor link to this section for reference")

Middleware that automatically retries failed tool calls with configurable backoff.

Supports retrying on specific exceptions and exponential backoff.

Examples:

Basic usage with default settings (2 retries, exponential backoff):

```
from langchain.agents import create_agent
from langchain.agents.middleware import ToolRetryMiddleware

agent = create_agent(model, tools=[search_tool], middleware=[ToolRetryMiddleware()])
```

Retry specific exceptions only:

```
from requests.exceptions import RequestException, Timeout

retry = ToolRetryMiddleware(
    max_retries=4,
    retry_on=(RequestException, Timeout),
    backoff_factor=1.5,
)
```

Custom exception filtering:

```
from requests.exceptions import HTTPError


def should_retry(exc: Exception) -> bool:
    # Only retry on 5xx errors
    if isinstance(exc, HTTPError):
        return 500 <= exc.status_code < 600
    return False


retry = ToolRetryMiddleware(
    max_retries=3,
    retry_on=should_retry,
)
```

Apply to specific tools with custom error handling:

```
def format_error(exc: Exception) -> str:
    return "Database temporarily unavailable. Please try again later."


retry = ToolRetryMiddleware(
    max_retries=4,
    tools=["search_database"],
    on_failure=format_error,
)
```

Apply to specific tools using BaseTool instances:

```
from langchain_core.tools import tool


@tool
def search_database(query: str) -> str:
    '''Search the database.'''
    return results


retry = ToolRetryMiddleware(
    max_retries=4,
    tools=[search_database],  # Pass BaseTool instance
)
```

Constant backoff (no exponential growth):

```
retry = ToolRetryMiddleware(
    max_retries=5,
    backoff_factor=0.0,  # No exponential growth
    initial_delay=2.0,  # Always wait 2 seconds
)
```

Raise exception on failure:

```
retry = ToolRetryMiddleware(
    max_retries=2,
    on_failure="raise",  # Re-raise exception instead of returning message
)
```

| METHOD | DESCRIPTION |
| --- | --- |
| `__init__` | Initialize `ToolRetryMiddleware`. |

### \_\_init\_\_ [¶](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ToolRetryMiddleware.__init__ "Copy anchor link to this section for reference")

```
__init__(
    *,
    max_retries: int = 2,
    tools: list[BaseTool | str] | None = None,
    retry_on: tuple[type[Exception], ...] | Callable[[Exception], bool] = (Exception,),
    on_failure: Literal["raise", "return_message"]
    | Callable[[Exception], str] = "return_message",
    backoff_factor: float = 2.0,
    initial_delay: float = 1.0,
    max_delay: float = 60.0,
    jitter: bool = True,
) -> None
```

Initialize `ToolRetryMiddleware`.

| PARAMETER | DESCRIPTION |
| --- | --- |
| `max_retries` | Maximum number of retry attempts after the initial call. Default is `2` retries (`3` total attempts). Must be `>= 0`.  **TYPE:** `int`  **DEFAULT:** `2` |
| `tools` | Optional list of tools or tool names to apply retry logic to.  Can be a list of `BaseTool` instances or tool name strings.  If `None`, applies to all tools.  **TYPE:** `list[BaseTool | str] | None`  **DEFAULT:** `None` |
| `retry_on` | Either a tuple of exception types to retry on, or a callable that takes an exception and returns `True` if it should be retried.  Default is to retry on all exceptions.  **TYPE:** `tuple[type[Exception], ...] | Callable[[Exception], bool]`  **DEFAULT:** `(Exception,)` |
| `on_failure` | Behavior when all retries are exhausted. Options:   * `'return_message'`: Return a `ToolMessage` with error details,   allowing the LLM to handle the failure and potentially recover. * `'raise'`: Re-raise the exception, stopping agent execution. * Custom callable: Function that takes the exception and returns a   string for the `ToolMessage` content, allowing custom error   formatting.  **TYPE:** `Literal['raise', 'return_message'] | Callable[[Exception], str]`  **DEFAULT:** `'return_message'` |
| `backoff_factor` | Multiplier for exponential backoff.  Each retry waits `initial_delay * (backoff_factor ** retry_number)` seconds.  Set to `0.0` for constant delay.  **TYPE:** `float`  **DEFAULT:** `2.0` |
| `initial_delay` | Initial delay in seconds before first retry.  **TYPE:** `float`  **DEFAULT:** `1.0` |
| `max_delay` | Maximum delay in seconds between retries.  Caps exponential backoff growth.  **TYPE:** `float`  **DEFAULT:** `60.0` |
| `jitter` | Whether to add random jitter (`±25%`) to delay to avoid thundering herd.  **TYPE:** `bool`  **DEFAULT:** `True` |

| RAISES | DESCRIPTION |
| --- | --- |
| `ValueError` | If `max_retries < 0` or delays are negative. |

## langchain.agents.middleware.LLMToolEmulator [¶](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.LLMToolEmulator "Copy anchor link to this section for reference")

Emulates specified tools using an LLM instead of executing them.

This middleware allows selective emulation of tools for testing purposes.

By default (when `tools=None`), all tools are emulated. You can specify which
tools to emulate by passing a list of tool names or BaseTool instances.

Examples:

Emulate all tools (default behavior)

```
from langchain.agents.middleware import LLMToolEmulator

middleware = LLMToolEmulator()

agent = create_agent(
    model="openai:gpt-4o",
    tools=[get_weather, get_user_location, calculator],
    middleware=[middleware],
)
```

Emulate specific tools by name

```
middleware = LLMToolEmulator(tools=["get_weather", "get_user_location"])
```

Use a custom model for emulation

```
middleware = LLMToolEmulator(
    tools=["get_weather"], model="anthropic:claude-sonnet-4-5-20250929"
)
```

Emulate specific tools by passing tool instances

```
middleware = LLMToolEmulator(tools=[get_weather, get_user_location])
```

| METHOD | DESCRIPTION |
| --- | --- |
| `__init__` | Initialize the tool emulator. |

### \_\_init\_\_ [¶](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.LLMToolEmulator.__init__ "Copy anchor link to this section for reference")

```
__init__(
    *,
    tools: list[str | BaseTool] | None = None,
    model: str | BaseChatModel | None = None,
) -> None
```

Initialize the tool emulator.

| PARAMETER | DESCRIPTION |
| --- | --- |
| `tools` | List of tool names (`str`) or `BaseTool` instances to emulate.  If `None`, ALL tools will be emulated.  If empty list, no tools will be emulated.  **TYPE:** `list[str | BaseTool] | None`  **DEFAULT:** `None` |
| `model` | Model to use for emulation.  Defaults to `'anthropic:claude-sonnet-4-5-20250929'`.  Can be a model identifier string or `BaseChatModel` instance.  **TYPE:** `str | BaseChatModel | None`  **DEFAULT:** `None` |

## langchain.agents.middleware.ContextEditingMiddleware [¶](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ContextEditingMiddleware "Copy anchor link to this section for reference")

Automatically prune tool results to manage context size.

The middleware applies a sequence of edits when the total input token count exceeds
configured thresholds.

Currently the `ClearToolUsesEdit` strategy is supported, aligning with Anthropic's
`clear_tool_uses_20250919` behavior [(read more)](https://docs.claude.com/en/docs/agents-and-tools/tool-use/memory-tool).

| METHOD | DESCRIPTION |
| --- | --- |
| `__init__` | Initialize an instance of context editing middleware. |

### \_\_init\_\_ [¶](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ContextEditingMiddleware.__init__ "Copy anchor link to this section for reference")

```
__init__(
    *,
    edits: Iterable[ContextEdit] | None = None,
    token_count_method: Literal["approximate", "model"] = "approximate",
) -> None
```

Initialize an instance of context editing middleware.

| PARAMETER | DESCRIPTION |
| --- | --- |
| `edits` | Sequence of edit strategies to apply.  Defaults to a single `ClearToolUsesEdit` mirroring Anthropic defaults.  **TYPE:** `Iterable[ContextEdit] | None`  **DEFAULT:** `None` |
| `token_count_method` | Whether to use approximate token counting (faster, less accurate) or exact counting implemented by the chat model (potentially slower, more accurate).  **TYPE:** `Literal['approximate', 'model']`  **DEFAULT:** `'approximate'` |

## langchain.agents.middleware.ShellToolMiddleware [¶](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ShellToolMiddleware "Copy anchor link to this section for reference")

Middleware that registers a persistent shell tool for agents.

The middleware exposes a single long-lived shell session. Use the execution policy
to match your deployment's security posture:

* `HostExecutionPolicy` – full host access; best for trusted environments where the
  agent already runs inside a container or VM that provides isolation.
* `CodexSandboxExecutionPolicy` – reuses the Codex CLI sandbox for additional
  syscall/filesystem restrictions when the CLI is available.
* `DockerExecutionPolicy` – launches a separate Docker container for each agent run,
  providing harder isolation, optional read-only root filesystems, and user
  remapping.

When no policy is provided the middleware defaults to `HostExecutionPolicy`.

| METHOD | DESCRIPTION |
| --- | --- |
| `__init__` | Initialize the middleware. |

### \_\_init\_\_ [¶](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.ShellToolMiddleware.__init__ "Copy anchor link to this section for reference")

```
__init__(
    workspace_root: str | Path | None = None,
    *,
    startup_commands: tuple[str, ...] | list[str] | str | None = None,
    shutdown_commands: tuple[str, ...] | list[str] | str | None = None,
    execution_policy: BaseExecutionPolicy | None = None,
    redaction_rules: tuple[RedactionRule, ...] | list[RedactionRule] | None = None,
    tool_description: str | None = None,
    tool_name: str = SHELL_TOOL_NAME,
    shell_command: Sequence[str] | str | None = None,
    env: Mapping[str, Any] | None = None,
) -> None
```

Initialize the middleware.

| PARAMETER | DESCRIPTION |
| --- | --- |
| `workspace_root` | Base directory for the shell session.  If omitted, a temporary directory is created when the agent starts and removed when it ends.  **TYPE:** `str | Path | None`  **DEFAULT:** `None` |
| `startup_commands` | Optional commands executed sequentially after the session starts.  **TYPE:** `tuple[str, ...] | list[str] | str | None`  **DEFAULT:** `None` |
| `shutdown_commands` | Optional commands executed before the session shuts down.  **TYPE:** `tuple[str, ...] | list[str] | str | None`  **DEFAULT:** `None` |
| `execution_policy` | Execution policy controlling timeouts, output limits, and resource configuration.  Defaults to `HostExecutionPolicy` for native execution.  **TYPE:** `BaseExecutionPolicy | None`  **DEFAULT:** `None` |
| `redaction_rules` | Optional redaction rules to sanitize command output before returning it to the model.  **TYPE:** `tuple[RedactionRule, ...] | list[RedactionRule] | None`  **DEFAULT:** `None` |
| `tool_description` | Optional override for the registered shell tool description.  **TYPE:** `str | None`  **DEFAULT:** `None` |
| `tool_name` | Name for the registered shell tool.  Defaults to `"shell"`.  **TYPE:** `str`  **DEFAULT:** `SHELL_TOOL_NAME` |
| `shell_command` | Optional shell executable (string) or argument sequence used to launch the persistent session.  Defaults to an implementation-defined bash command.  **TYPE:** `Sequence[str] | str | None`  **DEFAULT:** `None` |
| `env` | Optional environment variables to supply to the shell session.  Values are coerced to strings before command execution. If omitted, the session inherits the parent process environment.  **TYPE:** `Mapping[str, Any] | None`  **DEFAULT:** `None` |

## langchain.agents.middleware.FilesystemFileSearchMiddleware [¶](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.FilesystemFileSearchMiddleware "Copy anchor link to this section for reference")

Provides Glob and Grep search over filesystem files.

This middleware adds two tools that search through local filesystem:

* Glob: Fast file pattern matching by file path
* Grep: Fast content search using ripgrep or Python fallback

Example

```
from langchain.agents import create_agent
from langchain.agents.middleware import (
    FilesystemFileSearchMiddleware,
)

agent = create_agent(
    model=model,
    tools=[],  # Add tools as needed
    middleware=[
        FilesystemFileSearchMiddleware(root_path="/workspace"),
    ],
)
```

| METHOD | DESCRIPTION |
| --- | --- |
| `__init__` | Initialize the search middleware. |

### \_\_init\_\_ [¶](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.FilesystemFileSearchMiddleware.__init__ "Copy anchor link to this section for reference")

```
__init__(
    *, root_path: str, use_ripgrep: bool = True, max_file_size_mb: int = 10
) -> None
```

Initialize the search middleware.

| PARAMETER | DESCRIPTION |
| --- | --- |
| `root_path` | Root directory to search.  **TYPE:** `str` |
| `use_ripgrep` | Whether to use ripgrep for search.  Falls back to Python if ripgrep unavailable.  **TYPE:** `bool`  **DEFAULT:** `True` |
| `max_file_size_mb` | Maximum file size to search in MB.  **TYPE:** `int`  **DEFAULT:** `10` |

Back to top